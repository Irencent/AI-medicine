import os
import shutil
import csv
import re
import pydicom
import SimpleITK as sitk
import numpy as np
from PIL import Image
import pandas as pd
from tqdm import tqdm

import multiprocessing
import concurrent.futures
from concurrent.futures import ProcessPoolExecutor, as_completed

def filter_dicom_files(dataroot, pats_id_to_filter):
    """
    Filter DICOM files based on patient ID.
    
    Args:
        dataroot (str): The root directory containing DICOM files.
        pats_id_to_filter (list): List of patient IDs to filter out.
        
    Returns:
        list: List of filtered DICOM file paths.
    """
    filtered_files = []
    
    for root, dirs, files in os.walk(dataroot):
        if len(dirs) == 0:
            for file in files:
                try:
                    info = pydicom.dcmread(os.path.join(root, file))
                    pats_id = str(info['0010', '0020'].value)

                    for pats in pats_id_to_filter:
                    
                        if pats in pats_id:
                            # Skip files with patient IDs in the filter list
                            filtered_files.append(os.path.join(root, file))

                    if info:
                        del info
                        
                except Exception as e:
                    tqdm.write(f"Error processing {os.path.join(root, file)}: {str(e)}")
    
    return filtered_files

def process_wrapper(patient_path):
    try:
        filter_dicom_files(patient_path, pats_id_to_filter = ['1928492', '2004300', '1907787'])
        return True, patient_path
    except Exception as e:
        return False, f"{patient_path} | Error: {str(e)}"

if __name__ == "__main__":

    # ä¿®å¤Windowså¤šè¿›ç¨‹ç¯å¢ƒä¸‹çš„ç‰¹æ®Šè®¾ç½®
    multiprocessing.freeze_support()

    root_dir = r"I:\å›¾åƒ"
    dataroots = [
             r'I:\å›¾åƒ\normal_2',
             r'I:\å›¾åƒ\RENJI\AMY',
             r'I:\å›¾åƒ\RENJI\ARVC',
             r'I:\å›¾åƒ\RENJI\DCM',
             r'I:\å›¾åƒ\RENJI\HCM',
             r'I:\å›¾åƒ\RENJI\HTN',
             r'I:\å›¾åƒ\RENJI\LVNC',
             r'I:\å›¾åƒ\RENJI\MI',
             r'I:\å›¾åƒ\RENJI\normal_1',
             r'I:\å›¾åƒ\RENJI\TIS',
             ]
    jpg_root = r"I:\processed_data_hys_new\imgs"

    # ============== æ ¹æ®é¡¶å±‚ç›®å½•åˆ†ç±»æ”¶é›†æ‚£è€…è·¯å¾„ ==============
    patient_paths = []

    for datatroot in dataroots:
        for cate_folder in os.listdir(datatroot):
            cate_path = os.path.join(datatroot, cate_folder)
            if not os.path.isdir(cate_path):
                continue

            # åˆ¤æ–­ç›®å½•ç±»å‹
            for patient_name in os.listdir(cate_path):
                patient_path = os.path.join(cate_path, patient_name)
                if os.path.isdir(patient_path):
                    patient_paths.append(patient_path)

    # ============== å¤šè¿›ç¨‹ä¼˜åŒ– ==============
    all_filtered_files = []  # æ–°å¢ï¼šå…¨å±€æ”¶é›†è¿‡æ»¤ç»“æœ
    unique_pats = set()      # æ–°å¢ï¼šç”¨äºæ‚£è€…IDå»é‡

    # ä½¿ç”¨è¿›ç¨‹æ± æ¥å¤„ç†æ¯ä¸ªæ‚£è€…è·¯å¾„
    max_workers = min(4, os.cpu_count())
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤ä»»åŠ¡ï¼ˆé¿å…ä¸»æ¨¡å—é‡è½½é—®é¢˜ï¼‰
        futures = {executor.submit(process_wrapper, patient_path): patient_path for patient_path in patient_paths}
        
        # ä½¿ç”¨è¿›åº¦æ¡æ¥æ˜¾ç¤ºå¤„ç†è¿›åº¦
        with tqdm(total=len(patient_paths), desc="ğŸš€ Processing Patients", unit="patient") as pbar:
            success_count = 0
            failed_log = []
            
            for future in as_completed(futures):
                status, msg, filtered = future.result()
                if status:
                    success_count += 1
                    all_filtered_files.extend(filtered)
                else:
                    failed_log.append(msg)
                pbar.update(1)
                pbar.set_postfix_str(f"OK: {success_count}, Failed: {len(failed_log)}")


    print("æ‰¾åˆ°çš„ç»“æœ:", all_filtered_files)